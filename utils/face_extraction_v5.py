import cv2
import numpy as np
import torch
from PIL import Image
from insightface.app import FaceAnalysis
from insightface.utils import face_align
from insightface.model_zoo.arcface_onnx import ArcFaceONNX
import os
import requests
import traceback
import sys
# ===================================================================================
# Part 1: DECA å…‰ç…§å›¾ç”Ÿæˆæ¨¡å— (æ¥è‡ªæ‚¨çš„ç¬¬äºŒä¸ªè„šæœ¬)
# ===================================================================================
# ã€é‡è¦ã€‘æ‚¨éœ€è¦ç¡®ä¿ decalib åº“å·²ç»æ­£ç¡®å®‰è£…ï¼Œå¹¶ä¸”å…¶ä¾èµ–é¡¹ä¹Ÿå·²å°±ç»ªã€‚
# æ¯”å¦‚é€šè¿‡: pip install decalib
# å¹¶ä¸”ï¼ŒDECAæ¨¡å‹éœ€è¦ç›¸å…³çš„æ•°æ®æ–‡ä»¶ï¼Œè¯·åŠ¡å¿…æ ¹æ®ä¸‹é¢çš„æ³¨é‡Šä¿®æ”¹è·¯å¾„ã€‚
# try:
sys.path.append('models/Relightable-Portrait-Animation')
from src.decalib.utils import util
from src.decalib.utils.tensor_cropper import transform_points
from src.decalib.deca import DECA
from src.decalib.utils.config import cfg as deca_cfg
# except ImportError:
#     print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ decalib åº“ã€‚")
#     print("è¯·ç¡®ä¿æ‚¨å·²ç»æ­£ç¡®å®‰è£…äº† DECA (decalib) åŠå…¶ä¾èµ–é¡¹ï¼Œå¹¶è®¾ç½®äº†æ­£ç¡®çš„Pythonç¯å¢ƒã€‚")
#     exit()

class FaceImageRender:
    def __init__(self, deca_data_path: str) -> None:
        """
        åˆå§‹åŒ– DECA æ¨¡å‹ã€‚
        
        Args:
            deca_data_path (str): å­˜æ”¾ DECA ç›¸å…³æ•°æ®ï¼ˆå¦‚ mask æ–‡ä»¶ï¼‰çš„ç›®å½•è·¯å¾„ã€‚
        """
        # --- å…³é”®ä¿®æ”¹ ---
        # ç§»é™¤äº†ç¡¬ç¼–ç çš„è·¯å¾„ï¼Œä½¿å…¶æ›´åŠ çµæ´»ã€‚
        # æ‚¨éœ€è¦æä¾›ä¸€ä¸ªåŒ…å« 'FLAME_masks_face-id.pkl' å’Œ 'FLAME_masks.pkl' çš„è·¯å¾„ã€‚
        flame_masks_face_id_path = os.path.join(deca_data_path, 'FLAME_masks_face-id.pkl')
        flame_masks_path = os.path.join(deca_data_path, 'FLAME_masks.pkl')

        if not os.path.exists(flame_masks_face_id_path) or not os.path.exists(flame_masks_path):
            raise FileNotFoundError(
                f"DECA mask æ–‡ä»¶æœªæ‰¾åˆ°! è¯·æ£€æŸ¥è·¯å¾„: '{deca_data_path}'"
            )

        # åˆå§‹åŒ– DECA æ¨¡å‹
        deca_cfg.model.use_tex = False 
        self.deca = DECA(config=deca_cfg)
        
        f_mask = np.load(flame_masks_face_id_path, allow_pickle=True, encoding='latin1')
        v_mask = np.load(flame_masks_path, allow_pickle=True, encoding='latin1')
        
        self.mask = {
            'v_mask': v_mask['face'].tolist(),
            'f_mask': f_mask['face'].tolist()
        }
        print("âœ… DECA æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚")

    def image_to_3dcoeff(self, rgb_image):
        """ä»å•å¼ å›¾åƒä¸­æå–DECAçš„3Dç³»æ•°"""
        with torch.no_grad():
            codedict, _ = self.deca.img_to_3dcoeff(rgb_image)
        return codedict

    def render_shape(self, shape, exp, pose, cam, light, tform, h, w):
        """ä½¿ç”¨ç»™å®šçš„3Dç³»æ•°æ¸²æŸ“å…‰ç…§å›¾"""
        with torch.no_grad():
            verts, _, _ = self.deca.flame(shape_params=shape, expression_params=exp, pose_params=pose)
            trans_verts = util.batch_orth_proj(verts, cam)
            trans_verts[:,:,1:] = -trans_verts[:,:,1:]

            points_scale = [self.deca.image_size, self.deca.image_size]
            trans_verts = transform_points(trans_verts, tform, points_scale, [h, w])

            shape_images, _, _, _, _ = self.deca.render.render_shape(
                verts, trans_verts, h=h, w=w, lights=light, images=None, return_grid=True, mask=self.mask
            )
            
            shape_images_np = shape_images.permute(0, 2, 3, 1).clamp(0, 1).detach().cpu().numpy()[0] * 255
        return shape_images_np

class ShadingGenerator:
    """ä¸€ä¸ªå°è£…å¥½çš„ã€ç”¨äºä»å•ä¸ªå›¾åƒç”Ÿæˆå…‰ç…§å›¾çš„ç±»"""
    def __init__(self, deca_data_path: str):
        self.fir = FaceImageRender(deca_data_path)

    def generate_from_image(self, face_image: np.ndarray):
        """
        ç›´æ¥ä»ä¸€ä¸ªNumpyå›¾åƒæ•°ç»„ç”Ÿæˆå…‰ç…§å›¾ã€‚
        
        Args:
            face_image (np.ndarray): è¾“å…¥çš„é¢éƒ¨å›¾åƒ (RGB, 512x512, np.uint8)ã€‚
            save_path (str): ç”Ÿæˆçš„å…‰ç…§å›¾ä¿å­˜è·¯å¾„ã€‚
        """
        # print("\n--- å¼€å§‹ç”Ÿæˆå…‰ç…§å›¾ ---")
        
        # 1. ä»å•ä¸ªå›¾åƒä¸­æå–æ‰€æœ‰éœ€è¦çš„3Dç³»æ•°
        # print("æ­£åœ¨æå–3Dç³»æ•°...")
        codedict = self.fir.image_to_3dcoeff(face_image)
        neutral_expression = torch.zeros_like(codedict["exp"])
        # 2. ä½¿ç”¨è‡ªèº«çš„ç³»æ•°è¿›è¡Œæ¸²æŸ“ (è‡ªå·±æä¾›å½¢çŠ¶ã€å§¿æ€ã€è¡¨æƒ…å’Œå…‰ç…§)
        # print("æ­£åœ¨æ¸²æŸ“å…‰ç…§å›¾...")
        final_shading = self.fir.render_shape(
            shape=codedict["shape"],
            exp=codedict["exp"],
            pose=codedict["pose"],
            cam=codedict["cam"],
            light=codedict["light"],
            tform=codedict["tform"],
            h=codedict["height"],
            w=codedict["width"]
        )
        
        img = Image.fromarray(np.uint8(final_shading))
        return img

# ===================================================================================
# Part 2: é¢éƒ¨ç‰¹å¾æå–æ¨¡å— (æ¥è‡ªæ‚¨çš„ç¬¬ä¸€ä¸ªè„šæœ¬)
# ===================================================================================
def rtn_face_get(self, img, face, img_size_factor=3):
    """è‡ªå®šä¹‰é¢éƒ¨å¯¹é½å‡½æ•°ï¼Œè£å‰ªåå†æ‰©å¤§åŒºåŸŸ"""
    landmarks = face.kps
    min_x, min_y = np.min(landmarks, axis=0)
    max_x, max_y = np.max(landmarks, axis=0)
    
    h, w = img.shape[:2]
    center_x, center_y = (min_x + max_x) / 2, (min_y + max_y) / 2
    box_size = max(max_x - min_x, max_y - min_y) * img_size_factor
    
    x1 = max(0, int(center_x - box_size/2))
    y1 = max(0, int(center_y - box_size/2))
    x2 = min(w, int(center_x + box_size/2))
    y2 = min(h, int(center_y + box_size/2))
      
    expanded_face = img[y1:y2, x1:x2]
    face.crop_face = cv2.resize(expanded_face, (512, 512))
    
    # if len(face.crop_face.shape) == 3 and face.crop_face.shape[2] == 3:
    #     face.crop_face = cv2.cvtColor(face.crop_face, cv2.COLOR_BGR2RGB)
    
    return face

class FaceExtractor:
    def __init__(self, providers=['CUDAExecutionProvider','CPUExecutionProvider'], ctx_id=0):
        self.providers = providers
        self.ctx_id = ctx_id
        self.app = self._init_face_analysis("buffalo_l", det_size=(512, 512))
        # print("âœ… InsightFace æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚")

    def _init_face_analysis(self, app_name, det_size=(512, 512)):
        app = FaceAnalysis(name=app_name, providers=self.providers)
        app.prepare(ctx_id=self.ctx_id, det_size=det_size)
        return app

    def extract_features(self, image_path, imgsize_scale_factor=3):
        """ä»è¾“å…¥å›¾åƒä¸­æå–é¢éƒ¨ç‰¹å¾ï¼Œè¿”å›é¢éƒ¨å›¾åƒå’ŒIDåµŒå…¥"""
        # print("\n--- å¼€å§‹æå–é¢éƒ¨ç‰¹å¾ ---")
        try:
            img = cv2.imread(image_path)
            if img is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ {image_path}")
            
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            faces = self.app.get(img_rgb)
            if not faces:
                raise ValueError("å›¾åƒä¸­æœªæ£€æµ‹åˆ°é¢éƒ¨")
            
            main_face = faces[0]
            
            # 1. æå–é¢éƒ¨IDåµŒå…¥
            faceid_embeds = torch.from_numpy(main_face.normed_embedding).unsqueeze(0)
            
            # 2. å¤„ç†ç”¨äºCLIPç¼–ç å™¨çš„é¢éƒ¨å›¾åƒ
            original_get = ArcFaceONNX.get
            try:
                ArcFaceONNX.get = lambda x, img, face: rtn_face_get(x, img, face, img_size_factor=imgsize_scale_factor)
                faces_crop = self.app.get(img_rgb)
                if faces_crop:
                    face_image = faces_crop[0].crop_face
                else:
                    face_image = face_align.norm_crop(img_rgb, landmark=main_face.kps, image_size=512)
            finally:
                ArcFaceONNX.get = original_get
            
            # print("âœ… é¢éƒ¨ç‰¹å¾æå–æˆåŠŸ!")
            return face_image, faceid_embeds
            
        except Exception as e:
            # print(f"âŒ é¢éƒ¨æå–é”™è¯¯: {e}")
            traceback.print_exc()
            return None, None

# ===================================================================================
# Part 3: ä¸»å‡½æ•°å…¥å£ (åˆå¹¶åçš„æ‰§è¡Œæµç¨‹)
# ===================================================================================
if __name__ == '__main__':
    # --- 1. å‡†å¤‡ç¯å¢ƒå’Œå‚æ•° ---
    
    # ã€ã€ã€*** é‡è¦ï¼šè¯·åœ¨æ­¤å¤„é…ç½®æ‚¨çš„è·¯å¾„ ***ã€‘ã€‘ã€‘
    # è¿™æ˜¯ DECA æ¨¡å‹æ‰€éœ€çš„æ•°æ®æ–‡ä»¶ï¼ˆå¦‚ FLAME_masks.pklï¼‰æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    # æ‚¨éœ€è¦å°† 'PATH_TO_YOUR_DECA_PROJECT/src/decalib/data' æ›¿æ¢ä¸ºæ‚¨çš„å®é™…è·¯å¾„ã€‚
    DECA_DATA_FOLDER = "models/Relightable-Portrait-Animation/src/decalib/data/" 
    
    # æ£€æŸ¥ DECA è·¯å¾„æ˜¯å¦å·²é…ç½®
    if DECA_DATA_FOLDER == "PATH_TO_YOUR_DECA_PROJECT/src/decalib/data":
        print("âŒ è­¦å‘Š: æ‚¨å°šæœªé…ç½® DECA æ•°æ®æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚")
        print(f"è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ `DECA_DATA_FOLDER` å˜é‡ï¼Œä½¿å…¶æŒ‡å‘æ­£ç¡®çš„ä½ç½®ã€‚")
        exit()

    # å®šä¹‰æµ‹è¯•å›¾ç‰‡å’Œè¾“å‡ºæ–‡ä»¶çš„åç§°
    image_url = "https://images.unsplash.com/photo-1669455715139-086b58707bff?q=80&w=1287&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    test_image_path = "test_face_input.jpg"
    extracted_face_path = "extracted_face.jpg"
    shading_map_path = "shading_map.jpg"

    # ä¸‹è½½æµ‹è¯•å›¾ç‰‡
    if not os.path.exists(test_image_path):
        try:
            print(f"æ­£åœ¨ä¸‹è½½æµ‹è¯•å›¾ç‰‡: {image_url}")
            response = requests.get(image_url)
            response.raise_for_status()
            with open(test_image_path, 'wb') as f:
                f.write(response.content)
            print(f"æµ‹è¯•å›¾ç‰‡å·²ä¿å­˜è‡³: {test_image_path}")
        except Exception as e:
            print(f"ä¸‹è½½æµ‹è¯•å›¾ç‰‡å¤±è´¥: {e}")
            exit()
    
    # --- 2. åˆå§‹åŒ–æ¨¡å‹ ---
    # æ ¹æ®æ‚¨çš„ç¡¬ä»¶é€‰æ‹© 'CPUExecutionProvider' æˆ– 'CUDAExecutionProvider'
    try:
        # ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ï¼Œæ¨¡å‹æ–‡ä»¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…
        face_extractor = FaceExtractor(providers=['CPUExecutionProvider'])
        shading_generator = ShadingGenerator(deca_data_path=DECA_DATA_FOLDER)
    except Exception as e:
        print(f"åœ¨åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿ onnxruntime, insightface, decalib ç­‰åº“å·²æ­£ç¡®å®‰è£…ã€‚")
        exit()

    # --- 3. æ‰§è¡Œé¢éƒ¨æå– ---
    face_image, faceid_embeds = face_extractor.extract_features(test_image_path,imgsize_scale_factor=3.0)
    face_image_shading, _ = face_extractor.extract_features(test_image_path,imgsize_scale_factor=6.0)
    # --- 4. å¦‚æœæå–æˆåŠŸï¼Œåˆ™ç”Ÿæˆå…‰ç…§å›¾ ---
    if face_image is not None and faceid_embeds is not None:
        # ä¿å­˜æå–å‡ºçš„é¢éƒ¨å›¾åƒï¼Œæ–¹ä¾¿æŸ¥çœ‹
        pil_img = Image.fromarray(face_image)
        pil_img.save(extracted_face_path)
        print(f"æå–å‡ºçš„é¢éƒ¨å›¾åƒå·²ä¿å­˜è‡³: {extracted_face_path}")
        
        # ç”Ÿæˆå…‰ç…§å›¾
        img = shading_generator.generate_from_image(
            face_image=face_image_shading
        )
        img.save(shading_map_path)
        print("\nğŸ‰ å…¨éƒ¨æµç¨‹æ‰§è¡Œå®Œæ¯•!")
        print(f" - æ‚¨å¯ä»¥æŸ¥çœ‹è¾“å…¥å›¾ç‰‡: {test_image_path}")
        print(f" - æå–å‡ºçš„æ ‡å‡†è„¸: {extracted_face_path}")
        print(f" - ç”Ÿæˆçš„å…‰ç…§å›¾: {shading_map_path}")

    else:
        print("\nâŒ æµç¨‹ä¸­æ–­: æœªèƒ½æˆåŠŸæå–é¢éƒ¨ç‰¹å¾ï¼Œæ— æ³•ç»§ç»­ç”Ÿæˆå…‰ç…§å›¾ã€‚")